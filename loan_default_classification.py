# -*- coding: utf-8 -*-
"""Loan Default Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HBtp2gzuPEofE60CyalMJbGWpFbEVXze

# ***Loan Default Classification - Logistic Regression***

***Tools & Pre-requesites:***

1. Core - Python & Machine Learning (Logistics Classification Algorithm)
2. IDE - Jupyter Notebook, Google Colab, Etc..,
3. Loan Defaulter - Dataset (Taken from the Kaggle.com)
4. Python.org - Download Python (latest version 3.11.3)
5. pypi.org - Python Packages.

****Classification Model****

**@ Install required Packages**
"""

!pip install pandas                  # Data Manipulation & Data Defintion
!pip install numpy                   # Mathmatical Operations
!pip install matplotlib              # Data Visualization
!pip install seaborn                 # Data Visualization
!pip install sklearn                 # Machine Learning Algorithm Package

"""**@ Import Packages**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
import seaborn as sns
from matplotlib.cm import get_cmap
from sklearn import preprocessing
from random import sample
from sklearn.preprocessing import OrdinalEncoder
import warnings # 
warnings.filterwarnings("ignore")
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.metrics import roc_curve, roc_auc_score

"""**@ Import the Dataset**"""

df = pd.read_csv('/content/drive/MyDrive/Loan Default.csv') # Imported the Dataset as df.

"""**@ Data Defintion**"""

df.info()          # Data Info or Description.

print('Total_Columns: ', len(df.columns),'\n')
print(df.columns,'\n')
print('Shape :',df.shape)           # Data Size or Length (Row, Column)

df.head(5)         # Dataset First 5 Lines.

df.tail(5)         # Dataset Last 5 Lines.

df.describe()       # Data Summary

"""**@ Data Visualization**

###### ***Single Variate Analysis***
"""

df.isna().sum()    # Check for the Null's

"""***Null Treatment: ---  Found a Null's in the "person_emp_length" and "loan_int_rate"***"""

# Replace the Null values with it's Mean.

df.iloc[:,7] = df.iloc[:,7].fillna(df.iloc[:,7].mean())
df.iloc[:,3] = df.iloc[:,3].fillna(df.iloc[:,3].mean())
df.isna().sum()    # Check for the Null's

# Check for Anamolies

# Loan Interest Rate
plt.subplot(1,4,1)
sns.boxplot(df.iloc[:,7], color = 'green')
plt.title("Loan Interest Rate", fontsize = 10)

# Person Employee Experiance
plt.subplot(1,4,3)
sns.boxplot(df.iloc[:,3], color = 'green')
plt.title("Person Employee Length", fontsize = 10)

# Skewness defines a measure of the asymmetry of a distribution
print('Skewness: ')
print(df.iloc[:,3].name,":", df.iloc[:,3].skew())
print(df.iloc[:,7].name,":", df.iloc[:,7].skew())

"""From the above Plots found that, **"Loan Interest Rate"** Attribute is in Linear. But for the **"Person Employee Length or Experiance"** is having a few **anamolies**, as we see in the above plot, a Few records have been at 120.

***Anamoly Treatment - Person Employee Length***
"""

# Replacing the Anamolies with its 90% quantile value.

df.iloc[:,3] = np.where(df.iloc[:,3] > df.iloc[:,3].quantile(0.90), df.iloc[:,3].quantile(0.90), df.iloc[:,3])
df.iloc[:,3].describe()

# Converting the Categorical Text values into Numerical Values using Ordinal Encoder.

ord_enc = OrdinalEncoder()
df[['person_home_ownership', 'loan_intent', 'loan_grade']] = ord_enc.fit_transform(df[['person_home_ownership', 'loan_intent', 'loan_grade']])
df[['person_home_ownership', 'loan_intent', 'loan_grade']].head(11)
df.describe()

# Unique Values in the individual Fields.

def unique(x):
    return len(df[x].unique())

number_unique_vals = {x: unique(x) for x in df.columns}
number_unique_vals

# Person Employee Experiance
plt.subplot(2,4,1)
sns.boxplot(df.iloc[:,3], color = 'green')
plt.title("Boxplot - Person Employee Length", fontsize = 10)

plt.subplot(2,4,2)
plt.hist(df.iloc[:,3], color = 'orange')
plt.title("Histogram - Person Employee Length", fontsize = 10)
plt.subplots_adjust(left=1.4, bottom=0.1, right=4, top=1.2)

print('Skewness: ')
print(df.iloc[:,3].name,":", df.iloc[:,3].skew())

"""###### ***Multi Variate Analysis***

CORRELATION PLOT
"""

plt.figure(figsize = (10,8))
corr = df.corr()
corr.style.background_gradient(cmap='coolwarm').set_precision(2)
#sns.heatmap(df.corr(),annot = True)
#plt.show()

"""**@ Data Modelling**"""

# Separation of Dependent Variable and Independent Variables.

X = df.loc[:,df.columns != 'loan_status']
Y = df.loc[:,df.columns == 'loan_status']

# Train and Test Data Split with the ratio of 80% : 20%

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size = 0.8, random_state = 42)

print('x_train shape :', x_train.shape)
print('x_test shape :', x_test.shape)
print('y_train shape :', y_train.shape)
print('y_test shape :', y_test.shape)

# Model Fitting in the Algorithm

model = LogisticRegression(C=0.01, penalty='l1', solver='liblinear')
model.fit(x_train, y_train)

# Train and Test Accuracy 

print("Showing Performance Metrics for Logistic Regression\n")

print ("Training Accuracy: {}".format(model.score(x_train, y_train)))
predicted = model.predict(x_test)
print ("Testing Accuracy: {}".format(accuracy_score(y_test, predicted)))

# Confusion Matrix 

labels = [0, 1]
cm = confusion_matrix(y_test, predicted, labels=labels)
print(cm)

"""1. Precision: Percentage of correct positive predictions relative to total positive predictions.

2. Recall: Percentage of correct positive predictions relative to total actual positives.

3. F1 Score: A weighted harmonic mean of precision and recall. The closer to 1, the better the model.

F1 Score: 2 * (Precision * Recall) / (Precision + Recall)
"""

# Precision, Recall & F1 Scores.

print('Precision, Recall and f-1 Scores for Logistic Regression\n')
print(classification_report(y_test, predicted))

"""The AUROC is a way to measure how robust your model is across decision thresholds. It is the area under the plot of the true positive rate versus the false positive rate. The true positive rate (TPR) is (true positives)/(true positives + false negatives). The false positive rate is the (false positive)/(false positive + true negative)"""

# AUROC [Area Under Receiver-Operator Curve]

y_pred_proba = model.predict_proba(np.array(x_test))[:,1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)

sns.set()
plt.plot(fpr, tpr)
plt.plot(fpr, fpr, linestyle = '--', color = 'k')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
ROC = np.round(roc_auc_score(y_test, y_pred_proba), 2)
plt.title(f'Logistic Regression Model ROC curve; ROC: {ROC}');
plt.show()

"""***As per the Loan Defaulter Classification result, We got 83% Test Accuracy to define the test results. So, our results for the predictions are Approximately 83% Accurate as per the data.***"""